#!/bin/bash

loggertitle="$(basename ${0})[$$]"

# dont do anything if process is already running
if [ $(pgrep -f ${0} | wc -l) -gt 2 ]; then
    echo "[ERR] Process of ${0} is already running"
    logger -t $loggertitle "[ERR] Process of ${0} is already running"
    exit
fi

rm -f /root/.aws/credentials
service amazon-ssm-agent restart
sleep 10s
service awslogs restart
logger -t $loggertitle "Reloaded amazon-ssm-agent and awslogs"

# do some leftovers
CONFIG=$(cat /etc/rpi.json)
s3bucket="s3://"$(jq -r .aws.s3 <<< $CONFIG)
maindir=$(jq -r .maindir <<< $CONFIG)
ftpdir=$(jq -r .ftp.dir <<< $CONFIG)
wwwhtml="/var/www/html"

# take care of some failed files
find $maindir -name 'aws*.retry' -exec /etc/scripts/retry-files {} \;

# take care of timelapses
DATEDIR=`date +%Y/%m/%d`
CAM="cam1" # TODO make this dynamic from rpi.json
TMPLOCAL="$maindir/$CAM/$DATEDIR"
HOUR=$(date +"%H")

# make timelapse for yesterday
if [ $HOUR -eq 1 ]; then
    /etc/scripts/create-timelapse $CAM
fi

# move to S3 only in the hours from 1 to 5 AM
if [ $HOUR -ge 1 ] && [ $HOUR -lt 5 ] && [ -d $maindir/dailytimelapses ]; then

    find $maindir/dailytimelapses -type f -name "*.mp4" -print0 |
    while IFS= read -r -d $'\0' mp4; do
        # reference: https://github.com/tokland/youtube-upload
        #if [ -f /etc/youtube_client_secrets.json ]; then
        #    youtube-upload $mp4 \
        #        --title="Daily timelapse $(basename $mp4)" \
        #        --privacy="unlisted" \
        #        --client-secrets=/etc/youtube_client_secrets.json \
        #        --playlist="Timelapses-daily"
        #fi
        aws s3 mv $mp4 $s3bucket/dailytimelapses/ --acl public-read --only-show-errors \
            2>&1 | logger -t $loggertitle
    done

    if [ ${PIPESTATUS[0]} -ne 0 ]; then
        logger -t $loggertitle "[ERR] AWSCLI error code: ${PIPESTATUS[0]}"
    else
        logger -t $loggertitle "[OK] $LAPSEDIR/dailytimelapses/ files moved to S3"
        touch $LAPSEDIR/dailytimelapses/never.empty
    fi

fi

# delete files from tmp
find /tmp -mtime +1 -type f -name "*.retry" -exec rm -vf {} \; | logger -t $loggertitle
find /tmp -mmin +59 -type f -name "*.rebooted" -exec rm -vf {} \; | logger -t $loggertitle
find /tmp -mmin +59 -type f -name "*.jpg" -exec rm -vf {} \; | logger -t $loggertitle
find /tmp -mmin +59 -type f -name "*.conf" -exec rm -vf {} \; | logger -t $loggertitle

# delete old *.jpg files
find $maindir -mtime +5 -type f -name "*.jpg" -exec rm -vf {} \; | logger -t $loggertitle
# delete old timelapses
find $maindir -mtime +5 -type f -name "*.mp4" -exec rm -vf {} \; | logger -t $loggertitle
# wipe old temporary files
find $maindir -maxdepth 1 -mtime +10 -type f -exec rm -vf {} \; | logger -t $loggertitle
# wipe old files from ftp dir
find $ftpdir -mtime +14 -type f -exec rm -vf {} \; | logger -t $loggertitle
# delete empty dirs
find $maindir -mindepth 1 -mtime +1 -type d -empty -exec rm -vrf {} \; | logger -t $loggertitle
find $wwwhtml -mindepth 1 -mtime +1 -type d -empty -exec rm -vrf {} \; | logger -t $loggertitle
find $ftpdir -mindepth 1 -mtime +1 -type d -empty -exec rm -vrf {} \; | logger -t $loggertitle

# scan and configure directories for incron
find $ftpdir -mindepth 2 -type d -print0 |
while IFS= read -r -d $'\0' line; do
    echo "$line IN_CLOSE_WRITE /etc/scripts/incron-do \$% \$@ \$#" >> /tmp/track-these-dirs.conf
done
if [[ $(cmp --silent /tmp/track-these-dirs.conf /etc/incron.d/track-these-dirs.conf; echo $?) -ne 0 ]]; then
    logger -t $loggertitle "New dirs found. Update: $(mv -fv /tmp/track-these-dirs.conf /etc/incron.d/)"
else
    rm -f /tmp/track-these-dirs.conf
fi

# old data from tables cleanup
sqlite3 everything.db "DELETE FROM retried WHERE INSERT_DATE < datetime('now','-2 days');"
sqlite3 everything.db "DELETE FROM captures WHERE INSERT_DATE < datetime('now','-2 days');"
